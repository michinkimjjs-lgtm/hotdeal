import logging
import sys
import os
import time
from crawler import PpomppuCrawler, FMKoreaCrawler, RuliwebCrawler

# Configure Logging
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s [%(levelname)s] %(message)s',
    datefmt='%Y-%m-%d %H:%M:%S'
)
logger = logging.getLogger("crawler")

def main():
    logger.info("π€ [Cloud Runner] GitHub Actions ν¬λ΅¤λ§ μ‹μ‘")

    # Load Secrets from Environment Variables (GitHub Secrets)
    SUPABASE_URL = os.environ.get("SUPABASE_URL")
    SUPABASE_KEY = os.environ.get("SUPABASE_KEY")

    if not SUPABASE_URL:
        logger.error("β [μ¤λ¥] SUPABASE_URLμ΄ μ—†μµλ‹λ‹¤. Settings > Secretsμ— λ“±λ΅λμ—λ”μ§€ ν™•μΈν•΄μ£Όμ„Έμ”.")
    if not SUPABASE_KEY:
        logger.error("β [μ¤λ¥] SUPABASE_KEYκ°€ μ—†μµλ‹λ‹¤. Settings > Secretsμ— λ“±λ΅λμ—λ”μ§€ ν™•μΈν•΄μ£Όμ„Έμ”.")
    
    if not SUPABASE_URL or not SUPABASE_KEY:
        sys.exit(1)

    try:
        # Initialize Crawlers
        logger.info("π› οΈ ν¬λ΅¤λ¬ μ΄κΈ°ν™” μ¤‘...")
        ppomppu = PpomppuCrawler(SUPABASE_URL, SUPABASE_KEY)
        fmkorea = FMKoreaCrawler(SUPABASE_URL, SUPABASE_KEY)
        ruliweb = RuliwebCrawler(SUPABASE_URL, SUPABASE_KEY)

        # Run Crawlers
        logger.info("--- λ½λΏ ν¬λ΅¤λ§ μ‹μ‘ ---")
        ppomppu.crawl(limit=10) # 1ν μ‹¤ν–‰ μ‹ μµμ‹  10κ°λ§ ν™•μΈ (ν¨μ¨μ„±)
        
        logger.info("--- ν¨μ½” ν¬λ΅¤λ§ μ‹μ‘ ---")
        fmkorea.crawl(limit=10)

        logger.info("--- λ£¨λ¦¬μ›Ή ν¬λ΅¤λ§ μ‹μ‘ ---")
        ruliweb.crawl(limit=10)
        
        logger.info("β… λ¨λ“  ν¬λ΅¤λ§ μ‘μ—…μ΄ μ™„λ£λμ—μµλ‹λ‹¤.")

    except Exception as e:
        logger.error(f"β ν¬λ΅¤λ§ μ¤‘ μΉλ…μ μΈ μ¤λ¥ λ°μƒ: {e}", exc_info=True)
        sys.exit(1)

if __name__ == "__main__":
    main()
